{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netflix Movie Recommendation\n",
    "\n",
    "By : \n",
    "- Rakesh Reddy Poddutoori \n",
    "- Nakul Reddy Nimmala \n",
    "- Navya Gorantla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will be carrying out netflix movie recommendation, its about aiming to improve the accuracy of prediction of the netflix movies on the users preferences and ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "We first import the relevant libraries to carry out the processes.\n",
    "We then read in each of the files and create a DataFrame consisting of parsed lines.\n",
    "Here our source file is from netflix dataset with over 100000 ratings given to more then 17 thousand movies. It is a part of netflix user data issued for the netflix prize. This dataset provides movie name,year of release,ratings and a particular movie id assigned to each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import unittest as Test\n",
    "dbfs_dir = 's3://dsci6007movienetflix/Netflix/'#path to our s3 bucket sourcing our file\n",
    "ratings_filename = dbfs_dir + '/TestingRatings.txt'#source dataset\n",
    "movies_filename = dbfs_dir + '/movie_titles.txt'#supporting our dataset with movie names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we will import methods from pyspark which are very helpful in running our code in our EMR cluster works and initiate our variables to the values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "ratings_df_schema = StructType(\n",
    "  [StructField('userId', IntegerType()),\n",
    "   StructField('movieId', IntegerType()),\n",
    "   StructField('rating', DoubleType())]\n",
    ")\n",
    "movies_df_schema = StructType(\n",
    "  [StructField('ID', IntegerType()),\n",
    "   StructField('year', IntegerType()),\n",
    "   StructField('title', StringType()),]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Cache\n",
    "\n",
    "By now, the assigned datasets should be hosted on S3. We're going to be accessing this data a lot. Rather than read it over and over again from S3, we'll cache both the movies DataFrame and the ratings DataFrame in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100477 ratings and 17769 movies in the datasets\n",
      "Ratings:\n",
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     8|2149668|   3.0|\n",
      "|     8|1089184|   3.0|\n",
      "|     8|2465894|   3.0|\n",
      "+------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Movies:\n",
      "+---+----+----------------------------+\n",
      "|ID |year|title                       |\n",
      "+---+----+----------------------------+\n",
      "|2  |2004|Isle of Man TT 2004 Review  |\n",
      "|3  |1997|Character                   |\n",
      "|4  |1994|Paula Abdul's Get Up & Dance|\n",
      "+---+----+----------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "raw_ratings_df = sqlContext.read.format('csv').options(header=True, inferSchema=False).schema(ratings_df_schema).load(ratings_filename)\n",
    "ratings_df = raw_ratings_df.drop('Timestamp')\n",
    "\n",
    "raw_movies_df = sqlContext.read.format('csv').options(header=True, inferSchema=False).schema(movies_df_schema).load(movies_filename)\n",
    "movies_df = raw_movies_df.drop('Genres').withColumnRenamed('movieId', 'ID')\n",
    "\n",
    "ratings_df.cache()\n",
    "movies_df.cache()\n",
    "\n",
    "assert ratings_df.is_cached\n",
    "assert movies_df.is_cached\n",
    "\n",
    "raw_ratings_count = raw_ratings_df.count()\n",
    "ratings_count = ratings_df.count()\n",
    "raw_movies_count = raw_movies_df.count()\n",
    "movies_count = movies_df.count()\n",
    "\n",
    "print('There are %s ratings and %s movies in the datasets' % (ratings_count, movies_count))\n",
    "print('Ratings:')\n",
    "ratings_df.show(3)\n",
    "print('Movies:')\n",
    "movies_df.show(3, truncate=False)\n",
    "\n",
    "assert raw_ratings_count == ratings_count\n",
    "assert raw_movies_count == movies_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's do a quick verification of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at some of the data in the two DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ID: int, year: int, title: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: int, movieId: int, rating: double]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ratings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Recommendations\n",
    "\n",
    "One method of film recommendation is to always suggest the films with the highest average rating.\n",
    "We'll utilize Spark to identify the name, number of ratings, and average rating of the 20 films with the highest average rating and at least 500 reviews in this section.\n",
    "We want to filter our movies that have good ratings but less than or equal to 500 reviews because films with few reviews may not appeal to everyone. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Movies with Highest Average Ratings\n",
    "\n",
    "Let's determine the movies with the highest average ratings.\n",
    "The steps you performed here are:\n",
    "1. Recall that the `ratings_df` contains three columns:\n",
    "    - The ID of the user who rated the film\n",
    "    - the ID of the movie being rated\n",
    "    - and the rating.\n",
    "   First, we transform `ratings_df` into a second DataFrame, `movie_ids_with_avg_ratings`, with the following columns:\n",
    "    - The movie ID\n",
    "    - The number of ratings for the movie\n",
    "    - The average of all the movie's ratings\n",
    "2. Then, Transformation of `movie_ids_with_avg_ratings` to another DataFrame, `movie_names_with_avg_ratings_df` that adds the movie name to each row. `movie_names_with_avg_ratings_df`\n",
    "   will contain these columns:\n",
    "    - The movie ID\n",
    "    - The movie name\n",
    "    - The number of ratings for the movie\n",
    "    - The average of all the movie's ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_ids_with_avg_ratings_df:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 1) / 1]22/05/01 21:18:21 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-------+\n",
      "|movieId|count|average|\n",
      "+-------+-----+-------+\n",
      "|2358799|2    |3.5    |\n",
      "|973051 |4    |4.25   |\n",
      "|1189060|3    |3.0    |\n",
      "+-------+-----+-------+\n",
      "only showing top 3 rows\n",
      "\n",
      "movie_names_with_avg_ratings_df:\n",
      "+-------+-------------------+-----+-------+\n",
      "|average|title              |count|movieId|\n",
      "+-------+-------------------+-----+-------+\n",
      "|5.0    |Chaplin: The Movie |4    |8815   |\n",
      "|5.0    |Faith of My Fathers|1    |11215  |\n",
      "|5.0    |Fat City           |1    |6699   |\n",
      "+-------+-------------------+-----+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "# From ratingsDF, create a movie_ids_with_avg_ratings_df that combines the two DataFrames\n",
    "movie_ids_with_avg_ratings_df = ratings_df.groupBy('movieId').agg(F.count(ratings_df.rating).alias(\"count\"), F.avg(ratings_df.rating).alias(\"average\"))\n",
    "print('movie_ids_with_avg_ratings_df:')\n",
    "movie_ids_with_avg_ratings_df.show(3, truncate=False)\n",
    "# Note: movie_names_df is a temporary variable, used only to separate the steps necessary\n",
    "# to create the movie_names_with_avg_ratings_df DataFrame.\n",
    "movie_names_df = movie_ids_with_avg_ratings_df.join(movies_df,movies_df.ID==movie_ids_with_avg_ratings_df.movieId)\n",
    "movie_names_with_avg_ratings_df = movie_names_df.select('average','title','count','movieId').sort('average',ascending=False)\n",
    "\n",
    "print('movie_names_with_avg_ratings_df:')\n",
    "movie_names_with_avg_ratings_df.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test=unittest.TestCase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Movies with highest average ratings and at least with 500 reviews\n",
    "\n",
    "Now that we have a DataFrame of the movies with highest average ratings, we can use Spark to determine the 20 movies with highest average ratings and at least 500 reviews.\n",
    "We then add a single DataFrame transformation to limit the results to movies with ratings from at least 500 people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies with highest ratings:\n",
      "+------------------+------------------------------------+-----+-------+\n",
      "|average           |title                               |count|movieId|\n",
      "+------------------+------------------------------------+-----+-------+\n",
      "|3.8               |Un Chien Andalou                    |10   |5980   |\n",
      "|3.7               |Into the Sun                        |10   |16273  |\n",
      "|3.3636363636363638|Street Fighter Alpha                |11   |11796  |\n",
      "|3.272727272727273 |Madonna: The Drowned World Tour 2001|11   |12812  |\n",
      "|2.9375            |Crouching Tiger                     |16   |16272  |\n",
      "|2.7               |Mother's Day                        |10   |1333   |\n",
      "|2.2857142857142856|In Dreams                           |14   |3321   |\n",
      "+------------------+------------------------------------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_with_500_ratings_or_more = movie_names_with_avg_ratings_df.filter(movie_names_with_avg_ratings_df['count']>=10).sort('average',ascending=False)\n",
    "print('Movies with highest ratings:')\n",
    "movies_with_500_ratings_or_more.show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One technique to increase the quality of the recommendations is to set a threshold for the amount of reviews, but there are many additional options.\n",
    "For example, weight ratings based on the number of ratings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering\n",
    "\n",
    "For movie suggestions, we start with a matrix using movie ratings from users as entries.\n",
    "Each row represents a certain movie, while each column represents a user.\n",
    "We don't know all of the entries in this matrix because not all users have reviewed all of the movies, which is why we require collaborative filtering.\n",
    "We only have ratings for a portion of the movies for each user.\n",
    "The idea behind collaborative filtering is to factorize the ratings matrix as the product of two matrices: one that represents the attributes of each use and another that defines the properties of each movie. \n",
    "\n",
    "We want to use these two matrices so that the error for users/movie combinations for which we know the right ratings is as small as possible.\n",
    "The alternating least squares algorithm accomplishes this by randomly filling the users matrix with values and then optimizing the value of the movies to minimize the error.\n",
    "Then it optimizes the value of the user's matrix while keeping the movies matrix constant.\n",
    "The \"alternating\" in the name refers to the fact that the matrix to optimize changes from time to time.\n",
    "\n",
    "Using the optimization, we use the known ratings to obtain the optimal values for the movie factors.\n",
    "Then, given set movie factors, we \"alternate\" and choose the best user factors. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Creating a Training Set\n",
    "\n",
    "Before we use machine learning algorithms, we need to break up the `ratings_df` dataset into three pieces:\n",
    "* A training set (DataFrame), which we will use to train models\n",
    "* A validation set (DataFrame), which we will use to choose the best model\n",
    "* A test set (DataFrame), which we will use for our experiments\n",
    "To randomly split the dataset into the multiple groups, we can use the pySpark randomSplit() as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 60354, validation: 20041, test: 20082\n",
      "\n",
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     8|   9660|   3.0|\n",
      "|     8| 112790|   3.0|\n",
      "|     8| 155279|   3.0|\n",
      "+------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     8| 152955|   3.0|\n",
      "|     8| 394189|   2.0|\n",
      "|     8| 448155|   4.0|\n",
      "+------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     8| 254671|   4.0|\n",
      "|     8| 264988|   3.0|\n",
      "|     8| 500322|   3.0|\n",
      "+------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We'll hold out 60% for training, 20% of our data for validation, and leave 20% for testing\n",
    "seed = 1800009193\n",
    "(split_60_df, split_a_20_df, split_b_20_df) = ratings_df.randomSplit([0.60,0.20,0.20],seed)\n",
    "# Let's cache these datasets for performance\n",
    "training_df = split_60_df.cache()\n",
    "validation_df = split_a_20_df.cache()\n",
    "test_df = split_b_20_df.cache()\n",
    "print('Training: {0}, validation: {1}, test: {2}\\n'.format(\n",
    "  training_df.count(), validation_df.count(), test_df.count())\n",
    ")\n",
    "training_df.show(3)\n",
    "validation_df.show(3)\n",
    "test_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting the dataset, your training set has about 60354 entries and the validation and test sets each have about 20000 entries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Alternating Least Squares\n",
    "\n",
    "We'll utilize the Apache Spark ML Pipeline implementation of Alternating Least Squares.A training dataset and certain parameters that regulate the model construction process are passed to ALS.\n",
    "We'll use ALS to train numerous models to find the optimum values for the parameters, then pick the best model and utilize the parameters from that model in the rest of the lab session. \n",
    "The process we will use for determining the best model is as follows:\n",
    "\n",
    "1. Pick a set of model parameters. The most important parameter to model is the rank, which is the number of columns in the Users matrix or the number of rows in the Movies matrix. In general, a lower rank will mean higher error on the training dataset, but a high rank may lead to overfitting. \n",
    "\n",
    "2. Set the appropriate parameters on the `ALS` object:\n",
    "    * The \"User\" column will be set to the values in our `userId` DataFrame column.\n",
    "    * The \"Item\" column will be set to the values in our `movieId` DataFrame column.\n",
    "    * The \"Rating\" column will be set to the values in our `rating` DataFrame column.\n",
    "    * We'll using a regularization parameter of 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the RMSE is 4.22533894559318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 8 the RMSE is 2.8321088010878492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 203:===================================>                 (133 + 8) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 12 the RMSE is 2.7424852680717313\n",
      "The best model was trained with rank 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "# Let's initialize our ALS learner\n",
    "als = ALS()\n",
    "# Now we set the parameters for the method\n",
    "als.setMaxIter(5)\\\n",
    "   .setSeed(seed)\\\n",
    "   .setRegParam(0.1)\\\n",
    "   .setUserCol(\"userId\")\\\n",
    "   .setItemCol(\"movieId\")\\\n",
    "   .setRatingCol(\"rating\")\n",
    "\n",
    "# Now let's compute an evaluation metric for our test dataset\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Create an RMSE evaluator using the label and predicted columns\n",
    "reg_eval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"rating\", metricName=\"rmse\")\n",
    "\n",
    "tolerance = 0.03\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "models = [0, 0, 0]\n",
    "err = 0\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "for rank in ranks:\n",
    "  # Set the rank here:\n",
    "  als.setRank(rank)\n",
    "  # Create the model with these parameters.\n",
    "  model = als.fit(training_df)\n",
    "  # Run the model to create a prediction. Predict against the validation_df.\n",
    "  predict_df = model.transform(validation_df)\n",
    "\n",
    "  # Remove NaN values from prediction (due to SPARK-14489)\n",
    "  predicted_ratings_df = predict_df.filter(predict_df.prediction != float('nan'))\n",
    "\n",
    "  # Run the previously created RMSE evaluator, reg_eval, on the predicted_ratings_df DataFrame\n",
    "  error = reg_eval.evaluate(predicted_ratings_df)\n",
    "  errors[err] = error\n",
    "  models[err] = model\n",
    "  print ('For rank %s the RMSE is %s' % (rank, error))\n",
    "  if error < min_error:\n",
    "    min_error = error\n",
    "    best_rank = err\n",
    "  err += 1\n",
    "\n",
    "als.setRank(ranks[best_rank])\n",
    "print('The best model was trained with rank %s' % ranks[best_rank])\n",
    "my_model = models[best_rank]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Testing Your Model\n",
    "\n",
    "To date, we've selected the best model using the 'training df' and 'validation df' datasets.\n",
    "We can't use these two datasets to assess how well the model is because we used them to establish which model is best; otherwise, we'd be prone to overfitting.\n",
    "We'll use the 'test df' dataset to see how good our model is.\n",
    "We'll develop a model for predicting the ratings for the test dataset using the 'best rank' you determined in step (b), and then compute the RMSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 223:==============================================>      (177 + 8) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model had a RMSE on the test set of 2.7316792063322315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predict_df = my_model.transform(test_df)\n",
    "\n",
    "# Remove NaN values from prediction (due to SPARK-14489)\n",
    "predicted_test_df = predict_df.filter(predict_df.prediction != float('nan'))\n",
    "\n",
    "# Run the previously created RMSE evaluator, reg_eval, on the predicted_test_df DataFrame\n",
    "test_RMSE = reg_eval.evaluate(predicted_test_df)\n",
    "\n",
    "print('The model had a RMSE on the test set of {0}'.format(test_RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-----------+\n",
      "|userId|movieId|rating| prediction|\n",
      "+------+-------+------+-----------+\n",
      "|  2366| 124342|   4.0| 0.17026067|\n",
      "|  2366| 298900|   2.0|   2.295404|\n",
      "|  2366| 819822|   3.0|  1.4053096|\n",
      "|  2366| 934835|   4.0| 0.95326215|\n",
      "|  2366| 962019|   1.0|   2.202037|\n",
      "|  2366|1036350|   4.0|  3.8729734|\n",
      "|  2366|1059927|   4.0|-0.30296922|\n",
      "|  2366|1082263|   3.0|  1.7261463|\n",
      "|  2366|1269998|   1.0|  0.6576985|\n",
      "|  2366|1386053|   3.0|  1.4028765|\n",
      "|  2366|1417705|   1.0|  1.3606554|\n",
      "|  2366|1979447|   3.0|  2.8431706|\n",
      "| 11317| 828344|   2.0|  0.7400894|\n",
      "| 11317|1057992|   2.0|  1.4427508|\n",
      "| 11317|1258876|   3.0|  2.8689241|\n",
      "| 11317|1903604|   3.0|  0.8837402|\n",
      "| 11317|2281080|   3.0|  2.1490357|\n",
      "|  4190|1874239|   4.0|  2.0246134|\n",
      "|  9517|  78404|   4.0|-0.79945314|\n",
      "|  9517| 138649|   1.0| 0.41861713|\n",
      "+------+-------+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST Testing our Model (c)\n",
    "Test.assertTrue(abs(test_RMSE - 0.809624038485) < tolerance, 'incorrect test_RMSE: {0:.11f}'.format(test_RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Comparing our Model\n",
    "\n",
    "One technique to assess the quality of our model is to compare the RMSE of the model's projected results to the values in the test set.\n",
    "Another technique to assess the model is to assess the error from a test set in which each rating is the average of the training set's ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average rating for movies in the training set is 3.4815753719720317\n",
      "The RMSE on the average set is 1.0924531185162887\n"
     ]
    }
   ],
   "source": [
    "# Compute the average rating\n",
    "avg_rating_df = training_df.select('rating').agg(F.avg(\"rating\")).head(1)[0][0]\n",
    "\n",
    "print('The average rating for movies in the training set is {0}'.format(avg_rating_df))\n",
    "\n",
    "# Add a column with the average rating\n",
    "test_for_avg_df = test_df.withColumn('prediction', F.lit(avg_rating_df))\n",
    "\n",
    "# Run the previously created RMSE evaluator, reg_eval, on the test_for_avg_df DataFrame\n",
    "test_avg_RMSE = reg_eval.evaluate(test_for_avg_df)\n",
    "\n",
    "print(\"The RMSE on the average set is {0}\".format(test_avg_RMSE))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have code to predict how users will rate movies!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Predictions for ourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most rated movies:\n",
      "(average rating, movie name, number of reviews, movie ID)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(average=3.8, title='Un Chien Andalou', count=10, movieId=5980),\n",
       " Row(average=3.7, title='Into the Sun', count=10, movieId=16273),\n",
       " Row(average=3.3636363636363638, title='Street Fighter Alpha', count=11, movieId=11796),\n",
       " Row(average=3.272727272727273, title='Madonna: The Drowned World Tour 2001', count=11, movieId=12812),\n",
       " Row(average=2.9375, title='Crouching Tiger', count=16, movieId=16272),\n",
       " Row(average=2.7, title=\"Mother's Day\", count=10, movieId=1333),\n",
       " Row(average=2.2857142857142856, title='In Dreams', count=14, movieId=3321)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Most rated movies:')\n",
    "print('(average rating, movie name, number of reviews, movie ID)')\n",
    "display(movies_with_500_ratings_or_more.orderBy(movies_with_500_ratings_or_more['average'].desc()).take(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user ID 0 is unassigned, so we will use it for your ratings. We set the variable `my_user_ID` to 0 for you. Next, create a new DataFrame called `my_ratings_df`, with your ratings for at least 10 movie ratings. Each entry should be formatted as `(my_user_id, movieID, rating)`.  As in the original dataset, ratings should be between 1 and 5 (inclusive). If you have not seen at least 10 of these movies, you can increase the parameter passed to `take()` in the above cell until there are 10 movies that you have seen (or you can also guess what your rating would be for movies you have not seen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My movie ratings:\n",
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     0| 171011|     4|\n",
      "|     0|    905|     3|\n",
      "|     0|   2329|     3|\n",
      "|     0|  26082|     5|\n",
      "|     0|  26082|     4|\n",
      "|     0|   1234|     3|\n",
      "|     0|   1217|     5|\n",
      "|     0|   1136|     2|\n",
      "|     0|   5971|     4|\n",
      "|     0|   2571|     3|\n",
      "+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "my_user_id = 0\n",
    "\n",
    "# Note that the movie IDs are the *last* number on each line. A common error was to use the number of ratings as the movie ID.\n",
    "my_rated_movies = [\n",
    "     \n",
    "     # The format of each line is (my_user_id, movie ID, your rating)\n",
    "     # For example, to give the movie \"Star Wars: Episode IV - A New Hope (1977)\" a five rating, you would add the following line:\n",
    "     #   (my_user_id, 260, 5),\n",
    "    (my_user_id, 171011,  4),\n",
    "     (my_user_id, 905, 3),\n",
    "     (my_user_id, 2329,  3),\n",
    "     (my_user_id, 26082, 5),\n",
    "     (my_user_id, 26082,  4),\n",
    "     (my_user_id, 1234, 3),\n",
    "     (my_user_id, 1217, 5),\n",
    "     (my_user_id, 1136,  2),\n",
    "     (my_user_id, 5971, 4),\n",
    "     (my_user_id, 2571, 3) \n",
    "]\n",
    "\n",
    "my_ratings_df = sqlContext.createDataFrame(my_rated_movies, ['userId','movieId','rating'])\n",
    "print('My movie ratings:')\n",
    "my_ratings_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Add the Movies to Training Dataset\n",
    "Now that we have our own ratings, we must add them to the 'training' dataset so that the model we train will take the preferences into account.\n",
    "Spark's transformation joins two DataFrames together, using 'unionAll()' to generate a new training dataset that includes your ratings as well as the data from the original training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset now has 10 more entries than the original training dataset\n"
     ]
    }
   ],
   "source": [
    "training_with_my_ratings_df = training_df.unionAll(my_ratings_df)\n",
    "\n",
    "print ('The training dataset now has %s more entries than the original training dataset' %\n",
    "       (training_with_my_ratings_df.count() - training_df.count()))\n",
    "assert (training_with_my_ratings_df.count() - training_df.count()) == my_ratings_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Train a Model with Your Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the parameters for the ALS object.\n",
    "als.setPredictionCol(\"prediction\")\\\n",
    "   .setMaxIter(5)\\\n",
    "   .setSeed(seed)\\\n",
    "   .setUserCol(\"userId\")\\\n",
    "   .setItemCol(\"movieId\")\\\n",
    "   .setRatingCol(\"rating\")\\\n",
    "   .setRank(8)\n",
    "\n",
    "# Create the model with these parameters.\n",
    "my_ratings_model = als.fit(training_with_my_ratings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Check RMSE for the New Model with Your Ratings\n",
    "\n",
    "Compute the RMSE for this new model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 437:==================================>                  (131 + 8) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model had a RMSE on the test set of 2.840537106683272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "my_predict_df = my_ratings_model.transform(test_df)\n",
    "\n",
    "# Remove NaN values from prediction (due to SPARK-14489)\n",
    "predicted_test_my_ratings_df = my_predict_df.filter(my_predict_df.prediction != float('nan'))\n",
    "\n",
    "# Run the previously created RMSE evaluator, reg_eval, on the predicted_test_my_ratings_df DataFrame\n",
    "test_RMSE_my_ratings = reg_eval.evaluate(predicted_test_my_ratings_df)\n",
    "print('The model had a RMSE on the test set of {0}'.format(test_RMSE_my_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Predict the Ratings\n",
    "\n",
    "So far, we have only computed the error of the model.  Next, let's predict what ratings we would give to the movies that we did not already provide ratings for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of my rated movie IDs\n",
    "my_rated_movie_ids = [x[1] for x in my_rated_movies]\n",
    "# Filter out the movies I already rated.\n",
    "not_rated_df = movies_df.filter(~movies_df[\"ID\"].isin(my_rated_movie_ids))\n",
    "# Rename the \"ID\" column to be \"movieId\", and add a column with my_user_id as \"userId\".\n",
    "my_unrated_movies_df = not_rated_df.withColumn(\"userId\", F.lit(0)).withColumnRenamed(\"ID\",\"movieId\").drop('title').withColumn('rating',F.lit(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of my rated movie IDs\n",
    "my_rated_movie_ids = [x[1] for x in my_rated_movies]\n",
    "# Filter out the movies I already rated.\n",
    "not_rated_df = movies_df.filter(~movies_df[\"ID\"].isin(my_rated_movie_ids))\n",
    "# Rename the \"ID\" column to be \"movieId\", and add a column with my_user_id as \"userId\".\n",
    "my_unrated_movies_df = not_rated_df.withColumnRenamed(\"ID\", \"movieId\").withColumn(\"userId\",F.lit(my_user_id))\n",
    "raw_predicted_ratings_df = my_ratings_model.transform(my_unrated_movies_df)\n",
    "predicted_ratings_df = raw_predicted_ratings_df.filter(raw_predicted_ratings_df['prediction'] != float('nan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+--------------------+------+----------+\n",
      "|movieId|year|               title|userId|prediction|\n",
      "+-------+----+--------------------+------+----------+\n",
      "|      7|1992|               8 Man|     0|-3.1314156|\n",
      "|     79|1956|         The Killing|     0| 2.0580237|\n",
      "|    481|2002|Building the Grea...|     0|  1.332852|\n",
      "|    769|1958|    The Crawling Eye|     0| 2.7147417|\n",
      "|    906|1969|Benny Hill: Compl...|     0| 0.7379707|\n",
      "|   1310|2002|          Revelation|     0| 2.7935019|\n",
      "|   1333|1980|        Mother's Day|     0|  0.567906|\n",
      "|   1427|1998|            Sweepers|     0| 2.4487655|\n",
      "|   1442|2001|Sade: Life Promis...|     0|0.27922902|\n",
      "|   1457|1973|The White Seal / ...|     0|-2.2007918|\n",
      "|   1527|2003|   Hawaiian Paradise|     0| 0.8778585|\n",
      "|   1918|2004|           The Alamo|     0| 1.2805192|\n",
      "|   2000|1994|Four Weddings and...|     0| 1.7917471|\n",
      "|   2128|1993|                Rudy|     0| 1.9295458|\n",
      "|   2213|2000| Little Rascals #1-2|     0| 3.7195857|\n",
      "|   2225|1972|Chariots of the Gods|     0| 0.6315893|\n",
      "|   2307|2003|Denise Austin: Fa...|     0| 1.9174773|\n",
      "|   2455|1995|  Burnzy's Last Call|     0| 2.7424097|\n",
      "|   2469|2001|National Geograph...|     0| 3.0544956|\n",
      "|   2678|1996|     Price of Desire|     0| 0.7996334|\n",
      "+-------+----+--------------------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_ratings_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+--------------------+------+\n",
      "|movieId|year|               title|userId|\n",
      "+-------+----+--------------------+------+\n",
      "|      2|2004|Isle of Man TT 20...|     0|\n",
      "|      3|1997|           Character|     0|\n",
      "|      4|1994|Paula Abdul's Get...|     0|\n",
      "|      5|2004|The Rise and Fall...|     0|\n",
      "|      6|1997|                Sick|     0|\n",
      "|      7|1992|               8 Man|     0|\n",
      "|      8|2004|What the #$*! Do ...|     0|\n",
      "|      9|1991|Class of Nuke 'Em...|     0|\n",
      "|     10|2001|             Fighter|     0|\n",
      "|     11|1999|Full Frame: Docum...|     0|\n",
      "|     12|1947|My Favorite Brunette|     0|\n",
      "|     13|2003|Lord of the Rings...|     0|\n",
      "|     14|1982|  Nature: Antarctica|     0|\n",
      "|     15|1988|Neil Diamond: Gre...|     0|\n",
      "|     16|1996|           Screamers|     0|\n",
      "|     17|2005|           7 Seconds|     0|\n",
      "|     18|1994|    Immortal Beloved|     0|\n",
      "|     19|2000|By Dawn's Early L...|     0|\n",
      "|     20|1972|     Seeta Aur Geeta|     0|\n",
      "|     21|2002|   Strange Relations|     0|\n",
      "+-------+----+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_unrated_movies_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_predicted_ratings_df = my_ratings_model.transform(my_unrated_movies_df)\n",
    "predicted_ratings_df = raw_predicted_ratings_df.filter(raw_predicted_ratings_df['prediction'] != float('nan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+--------------------+------+----------+\n",
      "|movieId|year|               title|userId|prediction|\n",
      "+-------+----+--------------------+------+----------+\n",
      "|      7|1992|               8 Man|     0|-3.1314156|\n",
      "|     79|1956|         The Killing|     0| 2.0580237|\n",
      "|    481|2002|Building the Grea...|     0|  1.332852|\n",
      "|    769|1958|    The Crawling Eye|     0| 2.7147417|\n",
      "|    906|1969|Benny Hill: Compl...|     0| 0.7379707|\n",
      "|   1310|2002|          Revelation|     0| 2.7935019|\n",
      "|   1333|1980|        Mother's Day|     0|  0.567906|\n",
      "|   1427|1998|            Sweepers|     0| 2.4487655|\n",
      "|   1442|2001|Sade: Life Promis...|     0|0.27922902|\n",
      "|   1457|1973|The White Seal / ...|     0|-2.2007918|\n",
      "|   1527|2003|   Hawaiian Paradise|     0| 0.8778585|\n",
      "|   1918|2004|           The Alamo|     0| 1.2805192|\n",
      "|   2000|1994|Four Weddings and...|     0| 1.7917471|\n",
      "|   2128|1993|                Rudy|     0| 1.9295458|\n",
      "|   2213|2000| Little Rascals #1-2|     0| 3.7195857|\n",
      "|   2225|1972|Chariots of the Gods|     0| 0.6315893|\n",
      "|   2307|2003|Denise Austin: Fa...|     0| 1.9174773|\n",
      "|   2455|1995|  Burnzy's Last Call|     0| 2.7424097|\n",
      "|   2469|2001|National Geograph...|     0| 3.0544956|\n",
      "|   2678|1996|     Price of Desire|     0| 0.7996334|\n",
      "+-------+----+--------------------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_ratings_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.crossJoin.enabled\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+--------------------+------+-----------+\n",
      "|movieId|year|               title|userId| prediction|\n",
      "+-------+----+--------------------+------+-----------+\n",
      "|   7576|1953|        Kiss Me Kate|     0| 0.19918247|\n",
      "|   9597|1965|War-Gods of the Deep|     0|  1.9035152|\n",
      "|    481|2002|Building the Grea...|     0|   1.332852|\n",
      "|  15191|2003|           Figure 17|     0|   2.107647|\n",
      "|   6460|2005|The Game: The Doc...|     0| 0.55362666|\n",
      "|   2678|1996|     Price of Desire|     0|  0.7996334|\n",
      "|   3595|1988|              Elvira|     0|  1.1335566|\n",
      "|   7284|2005|        Morning Raga|     0|  3.2076926|\n",
      "|   9399|1991|Legend of the Dra...|     0|  2.5769486|\n",
      "|  17433|1936|    Follow the Fleet|     0| 0.92909527|\n",
      "|  14403|1996|The Long Kiss Goo...|     0|  1.0385376|\n",
      "|  15814|1941|           Suspicion|     0|   2.330772|\n",
      "|   7601|1943|Son of Dracula / ...|     0|  1.8285698|\n",
      "|  11462|1991|     Mortal Thoughts|     0|  1.5076497|\n",
      "|   3039|1967|Dark Shadows: Vol. 1|     0|-0.52973473|\n",
      "|  11215|2005| Faith of My Fathers|     0|  0.9000405|\n",
      "|   8095|2003|                Beef|     0|  -1.707242|\n",
      "|   4247|1998|     Velvet Goldmine|     0| 0.36855286|\n",
      "|   3694|1980|            Air Crew|     0|  1.7147629|\n",
      "|  10897|1978|                 Don|     0|  1.4834261|\n",
      "+-------+----+--------------------+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_ratings_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Predict the Ratings\n",
    "\n",
    "We have our predicted ratings. Now we can print out the 25 movies with the highest predicted ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My 25 highest rated movies as predicted (for movies with more than 75 reviews):\n",
      "+-------+----+--------+------+----------+-----------------+--------------------+-----+-------+\n",
      "|movieId|year|   title|userId|prediction|          average|               title|count|movieId|\n",
      "+-------+----+--------+------+----------+-----------------+--------------------+-----+-------+\n",
      "|   2905|1998|Croupier|     0| 4.7978663|              5.0|            Fat City|    1|   6699|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|4.333333333333333|Day of the Dead 2...|    3|   7921|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|              5.0|       The Red Shoes|    3|  14704|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|              5.0|               8 Man|    2|      7|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|              5.0|                 Rat|    3|  12876|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|              5.0|  Felicity: Season 2|    1|   4783|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|              5.0| Faith of My Fathers|    1|  11215|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|              5.0|  Chaplin: The Movie|    4|   8815|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|              5.0|Three's Company: ...|    1|   6529|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|              4.8|SpongeBob SquareP...|    5|   4409|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|4.666666666666667|  Along for the Ride|    3|  17451|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|4.666666666666667| Girls on Top: Set 1|    3|   7063|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|4.666666666666667|           Skin Deep|    3|   8158|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|4.666666666666667| Battle of the Bulge|    3|   4679|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|              4.6|    Follow the Fleet|    5|  17433|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|              4.5|Building the Grea...|    2|    481|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|              4.5|        Morning Raga|    2|   7284|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|              4.5|Point Pleasant: T...|    2|  16029|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|              4.5|  The Keeper of Time|    2|  10901|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|              4.5|          Affliction|    4|   3870|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|              4.5|   Seven Days in May|    4|   9964|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|              4.5|Far From Home: Th...|    2|   7134|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|              4.5|Why Do Fools Fall...|    2|   5977|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|              4.5|Baby Shakespeare:...|    2|   7133|\n",
      "|   2905|1998|Croupier|     0| 4.7978663|4.428571428571429|Joseph Campbell a...|    7|   3998|\n",
      "+-------+----+--------+------+----------+-----------------+--------------------+-----+-------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_with_counts_df = predicted_ratings_df.join(movie_names_with_avg_ratings_df)\n",
    "predicted_highest_rated_movies_df = predicted_with_counts_df.sort(F.col(\"prediction\").desc())\n",
    "print ('My 25 highest rated movies as predicted (for movies with more than 75 reviews):')\n",
    "predicted_highest_rated_movies_df.show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing the Top 25 Highest rated movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My 25 highest rated movies as predicted (for movies with more than 75 reviews):\n",
      "+------------------+--------------------+-------+-----+-----------+\n",
      "|           average|               title|movieId|count| prediction|\n",
      "+------------------+--------------------+-------+-----+-----------+\n",
      "| 4.428571428571429|Joseph Campbell a...|   3998|    7|  1.5132041|\n",
      "| 4.333333333333333|Mary Tyler Moore:...|  11043|    9|  1.0767839|\n",
      "| 4.166666666666667|Brotherhood of Ju...|  17421|    6|  3.2775755|\n",
      "|               4.0| Little Rascals #1-2|   2213|    6|  3.7195857|\n",
      "|               4.0|   O: Bonus Material|  16287|    6|  1.0035919|\n",
      "|               4.0|            Russkies|   5618|    6|   4.338407|\n",
      "|               3.8|    Un Chien Andalou|   5980|   10|  3.9360054|\n",
      "|3.7142857142857144|Stargate SG-1: Se...|   5530|    7|   2.372392|\n",
      "|               3.7|        Into the Sun|  16273|   10|    2.26118|\n",
      "|3.6666666666666665|           High Noon|  14642|    6|  2.5619767|\n",
      "|3.6666666666666665| Twelve O'Clock High|   5652|    6| -0.6016785|\n",
      "|3.6666666666666665|The Dead Sea Scrolls|   9850|    6|  3.1136837|\n",
      "|3.5714285714285716|  The Endless Summer|   7599|    7|  1.2455765|\n",
      "|3.5714285714285716|Buster Keaton Rid...|   4597|    7|  3.0912683|\n",
      "|               3.5|            Air Crew|   3694|    6|  1.7147629|\n",
      "|               3.5|Ben Folds Five: C...|  10943|    6|   1.147592|\n",
      "|               3.5|Battle Athletes V...|   9321|    6|  3.2462902|\n",
      "|3.3636363636363638|Street Fighter Alpha|  11796|   11| 0.75462747|\n",
      "|3.3333333333333335|       Francis Bacon|  16051|    6|  1.5398451|\n",
      "| 3.272727272727273|Madonna: The Drow...|  12812|   11|  2.6629345|\n",
      "|3.1666666666666665|Dario Argento Col...|  15737|    6|   4.022026|\n",
      "| 3.142857142857143|     The Incredibles|  10947|    7|  2.4405632|\n",
      "| 3.142857142857143|The Moonlight Exp...|  13432|    7|-0.78208435|\n",
      "| 3.111111111111111|P.D. James: A Min...|  13266|    9|   2.502502|\n",
      "|               3.0|                Grim|   3363|    6|  1.5894654|\n",
      "+------------------+--------------------+-------+-----+-----------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_with_counts_df = predicted_ratings_df.join(movie_names_with_avg_ratings_df,predicted_ratings_df.movieId==movie_names_with_avg_ratings_df.movieId).select(\"average\", movie_names_with_avg_ratings_df[\"title\"], movie_names_with_avg_ratings_df[\"movieId\"], \"count\",\"prediction\")\n",
    "predicted_highest_rated_movies_df = predicted_with_counts_df.filter(predicted_with_counts_df['count']>5 ).sort('average',ascending=False)\n",
    "print ('My 25 highest rated movies as predicted (for movies with more than 75 reviews):')\n",
    "predicted_highest_rated_movies_df.show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "We here successfully carried out our required process of predicting and creating the list of top 25 highest rated movies based on the given parameters and using the default resources of spark on Amazon EMR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "name": "W6L1: Recommender Systems - ALS Prediction",
  "notebookId": 2298298480838425
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
